{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T19:45:03.099711Z",
     "start_time": "2024-02-27T19:44:58.954944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0c/y7bd5j0d2t556b_zf587bmsw0000gn/T/ipykernel_64723/4048784357.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#torch.set_default_device('mps')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:33.550824Z",
     "start_time": "2024-02-24T10:25:33.539792Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:35.026158Z",
     "start_time": "2024-02-24T10:25:34.759793Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Data set is the AutoMPG Dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset = pd.read_csv(url, names=column_names,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:38.227115Z",
     "start_time": "2024-02-24T10:25:37.837643Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n393  27.0          4         140.0        86.0  2790.0          15.6   \n394  44.0          4          97.0        52.0  2130.0          24.6   \n395  32.0          4         135.0        84.0  2295.0          11.6   \n396  28.0          4         120.0        79.0  2625.0          18.6   \n397  31.0          4         119.0        82.0  2720.0          19.4   \n\n     Model Year  Origin  \n393          82       1  \n394          82       2  \n395          82       1  \n396          82       1  \n397          82       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MPG</th>\n      <th>Cylinders</th>\n      <th>Displacement</th>\n      <th>Horsepower</th>\n      <th>Weight</th>\n      <th>Acceleration</th>\n      <th>Model Year</th>\n      <th>Origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>393</th>\n      <td>27.0</td>\n      <td>4</td>\n      <td>140.0</td>\n      <td>86.0</td>\n      <td>2790.0</td>\n      <td>15.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>44.0</td>\n      <td>4</td>\n      <td>97.0</td>\n      <td>52.0</td>\n      <td>2130.0</td>\n      <td>24.6</td>\n      <td>82</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>32.0</td>\n      <td>4</td>\n      <td>135.0</td>\n      <td>84.0</td>\n      <td>2295.0</td>\n      <td>11.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>28.0</td>\n      <td>4</td>\n      <td>120.0</td>\n      <td>79.0</td>\n      <td>2625.0</td>\n      <td>18.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>31.0</td>\n      <td>4</td>\n      <td>119.0</td>\n      <td>82.0</td>\n      <td>2720.0</td>\n      <td>19.4</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:38.855385Z",
     "start_time": "2024-02-24T10:25:38.846173Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now procede to clean the data by removing the Nan and fixing other values.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "MPG             0\nCylinders       0\nDisplacement    0\nHorsepower      6\nWeight          0\nAcceleration    0\nModel Year      0\nOrigin          0\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:40.681417Z",
     "start_time": "2024-02-24T10:25:40.670470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:41.352822Z",
     "start_time": "2024-02-24T10:25:41.335881Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change categorical column\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n393  27.0          4         140.0        86.0  2790.0          15.6   \n394  44.0          4          97.0        52.0  2130.0          24.6   \n395  32.0          4         135.0        84.0  2295.0          11.6   \n396  28.0          4         120.0        79.0  2625.0          18.6   \n397  31.0          4         119.0        82.0  2720.0          19.4   \n\n     Model Year  Europe  Japan    USA  \n393          82   False  False   True  \n394          82    True  False  False  \n395          82   False  False   True  \n396          82   False  False   True  \n397          82   False  False   True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MPG</th>\n      <th>Cylinders</th>\n      <th>Displacement</th>\n      <th>Horsepower</th>\n      <th>Weight</th>\n      <th>Acceleration</th>\n      <th>Model Year</th>\n      <th>Europe</th>\n      <th>Japan</th>\n      <th>USA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>393</th>\n      <td>27.0</td>\n      <td>4</td>\n      <td>140.0</td>\n      <td>86.0</td>\n      <td>2790.0</td>\n      <td>15.6</td>\n      <td>82</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>44.0</td>\n      <td>4</td>\n      <td>97.0</td>\n      <td>52.0</td>\n      <td>2130.0</td>\n      <td>24.6</td>\n      <td>82</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>32.0</td>\n      <td>4</td>\n      <td>135.0</td>\n      <td>84.0</td>\n      <td>2295.0</td>\n      <td>11.6</td>\n      <td>82</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>28.0</td>\n      <td>4</td>\n      <td>120.0</td>\n      <td>79.0</td>\n      <td>2625.0</td>\n      <td>18.6</td>\n      <td>82</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>31.0</td>\n      <td>4</td>\n      <td>119.0</td>\n      <td>82.0</td>\n      <td>2720.0</td>\n      <td>19.4</td>\n      <td>82</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\n",
    "dataset.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:43.088913Z",
     "start_time": "2024-02-24T10:25:43.069504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_dataset:  (314, 10)\n",
      "shape of test_dataset:  (78, 10)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "print(\"shape of train_dataset: \", train_dataset.shape)\n",
    "print(\"shape of test_dataset: \", test_dataset.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:44.248101Z",
     "start_time": "2024-02-24T10:25:44.236350Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_features:  (314, 9)\n",
      "shape of test_features:  (78, 9)\n",
      "shape of train_labels:  (314,)\n",
      "shape of test_labels:  (78,)\n"
     ]
    }
   ],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('MPG')\n",
    "test_labels = test_features.pop('MPG')\n",
    "print(\"shape of train_features: \", train_features.shape)\n",
    "print(\"shape of test_features: \", test_features.shape)\n",
    "print(\"shape of train_labels: \", train_labels.shape)\n",
    "print(\"shape of test_labels: \", test_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:45.517904Z",
     "start_time": "2024-02-24T10:25:45.508821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:46.783426Z",
     "start_time": "2024-02-24T10:25:46.773527Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample batch:  [tensor([[5.0000e+00, 1.8300e+02, 7.7000e+01, 3.5300e+03, 2.0100e+01, 7.9000e+01,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0000e+00, 9.1000e+01, 5.3000e+01, 1.7950e+03, 1.7400e+01, 7.6000e+01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [4.0000e+00, 1.2000e+02, 7.4000e+01, 2.6350e+03, 1.8300e+01, 8.1000e+01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [4.0000e+00, 9.8000e+01, 6.3000e+01, 2.0510e+03, 1.7000e+01, 7.7000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [8.0000e+00, 3.0200e+02, 1.2900e+02, 3.1690e+03, 1.2000e+01, 7.5000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [6.0000e+00, 1.5500e+02, 1.0700e+02, 2.4720e+03, 1.4000e+01, 7.3000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [6.0000e+00, 1.6800e+02, 1.1600e+02, 2.9000e+03, 1.2600e+01, 8.1000e+01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [6.0000e+00, 1.5600e+02, 1.0800e+02, 2.9300e+03, 1.5500e+01, 7.6000e+01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [6.0000e+00, 2.2500e+02, 1.1000e+02, 3.3600e+03, 1.6600e+01, 7.9000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [4.0000e+00, 1.3400e+02, 9.6000e+01, 2.7020e+03, 1.3500e+01, 7.5000e+01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00]]), tensor([[25.4000],\n",
      "        [33.0000],\n",
      "        [31.6000],\n",
      "        [30.5000],\n",
      "        [13.0000],\n",
      "        [21.0000],\n",
      "        [25.4000],\n",
      "        [19.0000],\n",
      "        [20.6000],\n",
      "        [24.0000]])]\n",
      "batch len:  2\n"
     ]
    }
   ],
   "source": [
    "batch = 10\n",
    "X =np.array(train_features.values.astype(np.float32))\n",
    "X = torch.Tensor(X)\n",
    "y = np.array(train_labels.values.astype(np.float32))\n",
    "y = torch.Tensor(y)\n",
    "y = torch.reshape(y, (-1,1))\n",
    "train = TensorDataset(X,y)\n",
    "train_dataloader = DataLoader(train, batch_size=batch, shuffle=True)\n",
    "sample = next(iter(train_dataloader))\n",
    "print(\"sample batch: \", sample)\n",
    "print(\"batch len: \", len(sample))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:25:48.153124Z",
     "start_time": "2024-02-24T10:25:48.142973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [B, F]: torch.Size([10, 9])\n",
      "Shape of y [B, L]: torch.Size([10, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [B, F]: {X.shape}\")\n",
    "    print(f\"Shape of y [B, L]: {y.shape} {y.dtype}\")\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:26:58.758896Z",
     "start_time": "2024-02-24T10:26:58.748372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample batch:  tensor([[8.0000e+00, 4.0000e+02, 1.7000e+02, 4.7460e+03, 1.2000e+01, 7.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [4.0000e+00, 1.3500e+02, 8.4000e+01, 2.3850e+03, 1.2900e+01, 8.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [4.0000e+00, 8.5000e+01, 7.0000e+01, 1.9900e+03, 1.7000e+01, 7.6000e+01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [6.0000e+00, 2.2500e+02, 9.0000e+01, 3.3810e+03, 1.8700e+01, 8.0000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [8.0000e+00, 3.5000e+02, 1.7500e+02, 4.1000e+03, 1.3000e+01, 7.3000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [4.0000e+00, 1.1600e+02, 7.5000e+01, 2.1580e+03, 1.5500e+01, 7.3000e+01,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0000e+00, 1.1200e+02, 8.8000e+01, 2.6050e+03, 1.9600e+01, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [6.0000e+00, 2.0000e+02, 9.5000e+01, 3.1550e+03, 1.8200e+01, 7.8000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [8.0000e+00, 3.5100e+02, 1.5800e+02, 4.3630e+03, 1.3000e+01, 7.3000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [4.0000e+00, 7.2000e+01, 6.9000e+01, 1.6130e+03, 1.8000e+01, 7.1000e+01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00]])\n",
      "batch len:  2\n"
     ]
    }
   ],
   "source": [
    "X =np.array(test_features.values.astype(np.float32))\n",
    "X = torch.Tensor(X)\n",
    "y = np.array(test_labels.values.astype(np.float32))\n",
    "y = torch.Tensor(y)\n",
    "y = torch.reshape(y, (-1,1))\n",
    "test = TensorDataset(X,y)\n",
    "test_dataloader = DataLoader(test, batch_size=batch, shuffle=True)\n",
    "sample = next(iter(test_dataloader))\n",
    "print(\"sample batch: \", sample[0])\n",
    "print(\"batch len: \", len(sample))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:27:20.753454Z",
     "start_time": "2024-02-24T10:27:20.744397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [B, F]: torch.Size([10, 9])\n",
      "Shape of y [B, L]: torch.Size([10, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [B, F]: {X.shape}\")\n",
    "    print(f\"Shape of y [B, L]: {y.shape} {y.dtype}\")\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:28:17.096059Z",
     "start_time": "2024-02-24T10:28:17.086273Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class NNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #super(NNModel, self).__init__()\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm1d(9)\n",
    "        self.fc1 = nn.Linear(9,1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = self.norm(x)\n",
    "        t = self.fc1(t)\n",
    "        return t\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:28:26.559170Z",
     "start_time": "2024-02-24T10:28:26.546318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class NNModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        #super(NNModel, self).__init__()\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm1d(9)\n",
    "        self.fc1 = nn.Linear(9,18)\n",
    "        self.fc2 = nn.Linear(18,9)\n",
    "        self.fc3 = nn.Linear(9,1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = self.norm(x)\n",
    "        t = self.fc1(t)\n",
    "        t = self.relu(t)\n",
    "        t = self.fc2(t)\n",
    "        t = self.relu(t)\n",
    "        t = self.fc3(t)\n",
    "        return t"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:28:29.524280Z",
     "start_time": "2024-02-24T10:28:29.512520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class NNModel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        #super(NNModel, self).__init__()\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm1d(9)\n",
    "        self.fc1 = nn.Linear(9,18)\n",
    "        self.fc2 = nn.Linear(18,18)\n",
    "        self.fc3 = nn.Linear(18,9)\n",
    "        self.fc4 = nn.Linear(9,1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = self.norm(x)\n",
    "        t = self.fc1(t)\n",
    "        t = self.relu(t)\n",
    "        t = self.fc2(t)\n",
    "        t = self.relu(t)\n",
    "        t = self.fc3(t)\n",
    "        t = self.relu(t)\n",
    "        t = self.fc4(t)\n",
    "        return t"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:38:33.030843Z",
     "start_time": "2024-02-24T10:38:33.021603Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#nnet = NNModel()\n",
    "#nnet = NNModel2()\n",
    "nnet = NNModel3()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:42:49.565446Z",
     "start_time": "2024-02-24T10:42:49.556540Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "===================================================================================================================\nLayer (type:depth-idx)                   Input Shape               Output Shape              Param #\n===================================================================================================================\nNNModel3                                 [10, 9]                   [10, 1]                   --\n├─BatchNorm1d: 1-1                       [10, 9]                   [10, 9]                   18\n├─Linear: 1-2                            [10, 9]                   [10, 18]                  180\n├─ReLU: 1-3                              [10, 18]                  [10, 18]                  --\n├─Linear: 1-4                            [10, 18]                  [10, 18]                  342\n├─ReLU: 1-5                              [10, 18]                  [10, 18]                  --\n├─Linear: 1-6                            [10, 18]                  [10, 9]                   171\n├─ReLU: 1-7                              [10, 9]                   [10, 9]                   --\n├─Linear: 1-8                            [10, 9]                   [10, 1]                   10\n===================================================================================================================\nTotal params: 721\nTrainable params: 721\nNon-trainable params: 0\nTotal mult-adds (M): 0.01\n===================================================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.01\n==================================================================================================================="
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "batch = 10\n",
    "summary(nnet, input_size=(batch, 9), device='cpu', col_names=['input_size', 'output_size',\n",
    "                                                              'num_params'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:42:50.340118Z",
     "start_time": "2024-02-24T10:42:50.331519Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(\"size: \", size)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        #print(\"X: \" , X)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Train loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:42:51.698457Z",
     "start_time": "2024-02-24T10:42:51.691588Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(\"size: \", size)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:42:52.340298Z",
     "start_time": "2024-02-24T10:42:52.324674Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(nnet.parameters(), lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:42:53.805787Z",
     "start_time": "2024-02-24T10:42:53.792112Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 340.842468  [   10/  314]\n",
      "Train loss: 599.249390  [  110/  314]\n",
      "Train loss: 561.981445  [  210/  314]\n",
      "Train loss: 626.869751  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 636.788952 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 564.430847  [   10/  314]\n",
      "Train loss: 653.574402  [  110/  314]\n",
      "Train loss: 621.578064  [  210/  314]\n",
      "Train loss: 655.106506  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 617.460442 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 525.116943  [   10/  314]\n",
      "Train loss: 636.557495  [  110/  314]\n",
      "Train loss: 621.538879  [  210/  314]\n",
      "Train loss: 481.751862  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 541.538982 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 425.739410  [   10/  314]\n",
      "Train loss: 630.560730  [  110/  314]\n",
      "Train loss: 658.902405  [  210/  314]\n",
      "Train loss: 523.129517  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 299.032070 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 134.450089  [   10/  314]\n",
      "Train loss: 418.440887  [  110/  314]\n",
      "Train loss: 246.567337  [  210/  314]\n",
      "Train loss: 125.920364  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 54.570907 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 72.013680  [   10/  314]\n",
      "Train loss: 46.420135  [  110/  314]\n",
      "Train loss: 69.624596  [  210/  314]\n",
      "Train loss: 41.184486  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 33.635889 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 20.713743  [   10/  314]\n",
      "Train loss: 30.151550  [  110/  314]\n",
      "Train loss: 40.085506  [  210/  314]\n",
      "Train loss: 24.325691  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 25.219934 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 34.374416  [   10/  314]\n",
      "Train loss: 48.564762  [  110/  314]\n",
      "Train loss: 98.613113  [  210/  314]\n",
      "Train loss: 22.788509  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 16.397406 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 25.346231  [   10/  314]\n",
      "Train loss: 32.129791  [  110/  314]\n",
      "Train loss: 33.149002  [  210/  314]\n",
      "Train loss: 12.076154  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 13.572634 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 42.163483  [   10/  314]\n",
      "Train loss: 19.960646  [  110/  314]\n",
      "Train loss: 7.155785  [  210/  314]\n",
      "Train loss: 33.760933  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 13.246202 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 17.168940  [   10/  314]\n",
      "Train loss: 31.888899  [  110/  314]\n",
      "Train loss: 40.417381  [  210/  314]\n",
      "Train loss: 14.758575  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 11.526103 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 53.037384  [   10/  314]\n",
      "Train loss: 19.140182  [  110/  314]\n",
      "Train loss: 11.938457  [  210/  314]\n",
      "Train loss: 63.523121  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 12.280487 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 10.693519  [   10/  314]\n",
      "Train loss: 12.672194  [  110/  314]\n",
      "Train loss: 24.321440  [  210/  314]\n",
      "Train loss: 11.959239  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 12.013887 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 11.092408  [   10/  314]\n",
      "Train loss: 15.147702  [  110/  314]\n",
      "Train loss: 28.162399  [  210/  314]\n",
      "Train loss: 9.600899  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 10.375579 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 16.780989  [   10/  314]\n",
      "Train loss: 8.464940  [  110/  314]\n",
      "Train loss: 43.052746  [  210/  314]\n",
      "Train loss: 13.658748  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 10.964696 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 9.794600  [   10/  314]\n",
      "Train loss: 17.410812  [  110/  314]\n",
      "Train loss: 15.276209  [  210/  314]\n",
      "Train loss: 7.101537  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 10.078582 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 24.027319  [   10/  314]\n",
      "Train loss: 27.259909  [  110/  314]\n",
      "Train loss: 19.890518  [  210/  314]\n",
      "Train loss: 8.438017  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.435937 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 56.787777  [   10/  314]\n",
      "Train loss: 19.151495  [  110/  314]\n",
      "Train loss: 3.829384  [  210/  314]\n",
      "Train loss: 2.885148  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.273026 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 14.304517  [   10/  314]\n",
      "Train loss: 6.997337  [  110/  314]\n",
      "Train loss: 22.279196  [  210/  314]\n",
      "Train loss: 17.857822  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 10.203815 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 6.160192  [   10/  314]\n",
      "Train loss: 13.420044  [  110/  314]\n",
      "Train loss: 16.814756  [  210/  314]\n",
      "Train loss: 8.668387  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.147968 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 24.216345  [   10/  314]\n",
      "Train loss: 23.514767  [  110/  314]\n",
      "Train loss: 8.761301  [  210/  314]\n",
      "Train loss: 9.481394  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 10.015200 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 14.876708  [   10/  314]\n",
      "Train loss: 21.901081  [  110/  314]\n",
      "Train loss: 7.333189  [  210/  314]\n",
      "Train loss: 15.167244  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.848103 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 21.147932  [   10/  314]\n",
      "Train loss: 10.613368  [  110/  314]\n",
      "Train loss: 11.114044  [  210/  314]\n",
      "Train loss: 4.495582  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.743265 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 13.773345  [   10/  314]\n",
      "Train loss: 20.785303  [  110/  314]\n",
      "Train loss: 42.232265  [  210/  314]\n",
      "Train loss: 2.578381  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.655082 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 10.035285  [   10/  314]\n",
      "Train loss: 22.236984  [  110/  314]\n",
      "Train loss: 15.231821  [  210/  314]\n",
      "Train loss: 10.024974  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.864943 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 4.996757  [   10/  314]\n",
      "Train loss: 17.064734  [  110/  314]\n",
      "Train loss: 8.040747  [  210/  314]\n",
      "Train loss: 14.949849  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.184773 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 14.275703  [   10/  314]\n",
      "Train loss: 3.535053  [  110/  314]\n",
      "Train loss: 28.090498  [  210/  314]\n",
      "Train loss: 20.414316  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.327845 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 4.422998  [   10/  314]\n",
      "Train loss: 20.474039  [  110/  314]\n",
      "Train loss: 18.558649  [  210/  314]\n",
      "Train loss: 8.141599  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.014712 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 15.650449  [   10/  314]\n",
      "Train loss: 14.374404  [  110/  314]\n",
      "Train loss: 15.907081  [  210/  314]\n",
      "Train loss: 13.818593  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 9.103502 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "size:  314\n",
      "Train loss: 3.206518  [   10/  314]\n",
      "Train loss: 13.002143  [  110/  314]\n",
      "Train loss: 9.540928  [  210/  314]\n",
      "Train loss: 27.286383  [  310/  314]\n",
      "size:  78\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 8.381745 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "device = mps_device\n",
    "nnet = nnet.to(device=device)\n",
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, nnet, criterion, optimizer, device)\n",
    "    test(test_dataloader, nnet, criterion, device)\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:43:23.570843Z",
     "start_time": "2024-02-24T10:42:54.723508Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real labels:  tensor([[18.0000],\n",
      "        [19.0000],\n",
      "        [32.8000],\n",
      "        [ 9.0000],\n",
      "        [18.0000],\n",
      "        [29.0000],\n",
      "        [34.4000],\n",
      "        [14.0000],\n",
      "        [31.9000],\n",
      "        [16.0000]])\n",
      "Predicted labels:  tensor([[21.1999],\n",
      "        [26.9393],\n",
      "        [34.0011],\n",
      "        [14.6524],\n",
      "        [18.9318],\n",
      "        [28.1064],\n",
      "        [33.0574],\n",
      "        [14.0283],\n",
      "        [31.6110],\n",
      "        [15.8617]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "Demo done!\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(test_dataloader))\n",
    "Y = nnet(sample[0].to(device=device))\n",
    "print(\"Real labels: \", sample[1])\n",
    "print(\"Predicted labels: \", Y)\n",
    "print(\"Demo done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:43:29.562029Z",
     "start_time": "2024-02-24T10:43:29.525812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
